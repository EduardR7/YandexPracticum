{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для Викишоп с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Описание проекта](#0.Описание)\n",
    "    * [Описание проекта](#0.1.Цель)\n",
    "    * [План работ](#0.2.План)\n",
    "    * [Примечания к плану работ](#0.3.Прим)\n",
    "    * [Данные](#0.3.Данные)\n",
    "* [1. Загрузка и подготовка данных](#1.Глава1)\n",
    "    * [1.1. Импорт библиотек](#1.1.Импорт_библиотек)\n",
    "    * [1.2. Определение констант](#1.2.Опред_констант)\n",
    "    * [1.3. Загрузка данных](#1.3.Загрузка_данных)\n",
    "* [2. Подготовка признаков с BERT](#2.Подг_наборов)\n",
    "    * [2.1. Токенизация и инициализация pretrained модели](#2.1.Токенизация)\n",
    "    * [2.2. Разделение train, test ](#2.2.Таргет_Призн)\n",
    "* [3. Обучение моделей](#3.Обучение_мод)\n",
    "    * [3.1. Линейная регрессия](#3.1.LR)\n",
    "    * [3.2. Финальное тестирование](#3.2)\n",
    "* [4. Вывод](#4.Вывод)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта <a class=\"anchor\" id=\"0.Описание\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта <a class=\"anchor\" id=\"0.1.Цель\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "2. Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "3. Решить задачу можно как с помощью BERT, так и без этой нейронки. Если хотите попробовать BERT — Выполните проект локально. Упомяните BERT в заголовке проекта в первой ячейке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План работ <a class=\"anchor\" id=\"0.2.План\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузите данные\n",
    "2. Проанализируйте данные.\n",
    "3. Обучите разные модели с различными гиперпараметрами. Сделайте тестовую выборку размером 10% от исходных данных.\n",
    "4. Проверьте данные на тестовой выборке и сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных <a class=\"anchor\" id=\"1.Глава1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Импорт библиотек <a class=\"anchor\" id=\"1.1.Импорт_библиотек\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузим все необходимые библиотеки и инструменты\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer \n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import AutoModelForMaskedLM\n",
    "#from transformers import BERT\n",
    "\n",
    "#from transformers.utils import send_example_telemetry\n",
    "from tqdm import notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Определение констант <a class=\"anchor\" id=\"1.2.Опред_констант\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_STATE = 27182\n",
    "state = np.random.RandomState(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Загрузка и проверка данных <a class=\"anchor\" id=\"1.3.Загрузка_данных\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загружаем данные.\n",
    "2. Проверяем на NaN, мультиколинерность, дублирование категориальных признаков, лишние данные/столбцы.\n",
    "3. Убираем дублирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузился Path Windows!\n",
      "Path Yandex не загрузился!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    #df = pd.read_csv(r'c:\\%Users%\\datasets\\toxic_comments.csv')  r'c:\\Users\\e_rotar\\Documents\\yp\\pr13\\datasets\\toxic_comments.csv' \n",
    "    df = pd.read_csv(r'c:\\%Users%\\toxic_comments.csv')\n",
    "    print('Загрузился Path Windows!')\n",
    "except Exception:\n",
    "    print('Path Windows не загрузился!')\n",
    "    \n",
    "try:\n",
    "    df = pd.read_csv(r'/datasets/toxic_comments.csv')\n",
    "    print('Загрузился Path Yandex!')\n",
    "\n",
    "except Exception:\n",
    "    print('Path Yandex не загрузился!')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def about_df(df,sample_size=5, graph = True, categorical_ = False):\n",
    "    print(f'Первые {sample_size} строк')\n",
    "    display(df.head(sample_size))\n",
    "    print(f'Последние {sample_size} строк')\n",
    "    display(df.tail(sample_size))\n",
    "    print(f'\\n Основная информация')\n",
    "    print(df.info())\n",
    "    display(df.describe(include='all'))\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            np.array([df.isna().sum(), df.isna().mean()]).T,\n",
    "            columns = ['кол-во пропусков','доля пропусков'],\n",
    "            index=df.columns\n",
    "        ).style.background_gradient('coolwarm')\n",
    "    )\n",
    "    \n",
    "    print(f'\\n Кол-во и доля дубликатов')\n",
    "    \n",
    "    display( df.duplicated().head() )\n",
    "    print(1 - df.duplicated().value_counts()/len(df) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Проверяем df\n",
    "2. Функция проверки NaN, мультиколинерность, дублирование категориальных признаков, лишние данные/столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Последние 5 строк\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Основная информация\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>159292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0                                               text  \\\n",
       "count   159292.000000                                             159292   \n",
       "unique            NaN                                             159292   \n",
       "top               NaN  Explanation\\nWhy the edits made under my usern...   \n",
       "freq              NaN                                                  1   \n",
       "mean     79725.697242                                                NaN   \n",
       "std      46028.837471                                                NaN   \n",
       "min          0.000000                                                NaN   \n",
       "25%      39872.750000                                                NaN   \n",
       "50%      79721.500000                                                NaN   \n",
       "75%     119573.250000                                                NaN   \n",
       "max     159450.000000                                                NaN   \n",
       "\n",
       "                toxic  \n",
       "count   159292.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.101612  \n",
       "std          0.302139  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4dbf3_row0_col0, #T_4dbf3_row0_col1, #T_4dbf3_row1_col0, #T_4dbf3_row1_col1, #T_4dbf3_row2_col0, #T_4dbf3_row2_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4dbf3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4dbf3_level0_col0\" class=\"col_heading level0 col0\" >кол-во пропусков</th>\n",
       "      <th id=\"T_4dbf3_level0_col1\" class=\"col_heading level0 col1\" >доля пропусков</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4dbf3_level0_row0\" class=\"row_heading level0 row0\" >Unnamed: 0</th>\n",
       "      <td id=\"T_4dbf3_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_4dbf3_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dbf3_level0_row1\" class=\"row_heading level0 row1\" >text</th>\n",
       "      <td id=\"T_4dbf3_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_4dbf3_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dbf3_level0_row2\" class=\"row_heading level0 row2\" >toxic</th>\n",
       "      <td id=\"T_4dbf3_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_4dbf3_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2884b5f7340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Кол-во и доля дубликатов\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "about_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Проверил элементы столбца 'Unnamed: 0' с индексами (есть несовпадения с индекса 6080).\n",
    "2. Вероятно несовпадения случайные. Не уведел двух строк в одной. Столбец 'Unnamed: 0' не несет дополнительную информацию.\n",
    "3. Считаю столбец 'Unnamed: 0' ошибочным и удаляю его\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"::I\\'ll alos be looking in to see how this is going, as GRC is a big deal around these parts. Seek his grace \\n\\n\"'], [\"Active Members article \\n\\nHello. I don't think it is appropriate to add e-mail addresses or such information to a Wikipedia article, especially if it has no context. Will probably be deleted.\"], ['What is ALRs problem. Can someone please investiagate and sanction this user. Truthseekers666 (talk) Truthseekers666 Matthew Williams 2-2010   \"\"\"'], [\"Cubits, hogsheads, rods, chains, etc? \\n\\nSince we've got to have Imperial as well as Metric, maybe we should be adding all the above (and more)?  Jimbo must be off his nut...\"]]\n"
     ]
    }
   ],
   "source": [
    "#print(df[df['Unnamed: 0'] != df.index].head())\n",
    "#print(df.loc[159291,'Unnamed: 0'])\n",
    "err_txt=[]\n",
    "\n",
    "for i in range(6079,159291):\n",
    "    if ((df.loc[i-1,'Unnamed: 0']+1) !=df.loc[i,'Unnamed: 0']):\n",
    "        err_txt.append([df.loc[i,\"text\"]])\n",
    "            \n",
    "print(err_txt[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 'Unnamed: 0' не несет никакой информации.\n",
    "2. Убираем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверил по балансу toxic:\n",
    "1. Данные не сбалансированы, токсичных коментариев только 10%\n",
    "2. После подготовки данных проведем upsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10161213369158527\n"
     ]
    }
   ],
   "source": [
    "print(df['toxic'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Уменшил выборку до 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10161213369158527\n",
      "0.10860012554927809\n",
      "(1593, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df['toxic'].mean())\n",
    "df_ = df.sample(frac=0.01, random_state=RANDOM_STATE)\n",
    "print(df_['toxic'].mean())\n",
    "print(df_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подготовка признаков с BERT <a class=\"anchor\" id=\"2.Подг_наборов\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Токенизация и инициализация pretrained модели <a class=\"anchor\" id=\"2.1.Токенизация\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выполним токенизацию подготовленной моделью - BertTokenizer.from_pretrained\n",
    "2. Выполним классификацию токенов подготовленной моделью\n",
    "3. DistilBertModel загрузить корректно не получилось\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выполним энкодинг c помощью BERT.\n",
    "2. В результате использовался большой словарь токенов BertModel под 30 тыс. слов.\n",
    "3. Пришлось ограничить количество столбцов/векторов до 512. Модель создавалась для более мощных систем чем домашний комп.\n",
    "4. Применен метод padding, что-бы векторы в каждом тексте были равны.\n",
    "5. Подготовлена маска внимания/attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized = df_['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, padding=True, truncation=True))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "config = ppb.BertConfig.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.26.1\n"
     ]
    }
   ],
   "source": [
    "print(ppb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Распечатал токенайзер, что-бы иметь представление о модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='unitary/toxic-bert', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Токенизированная матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26447     [101, 2004, 4842, 15776, 1998, 1040, 7274, 144...\n",
      "155507    [101, 1038, 2094, 5443, 10930, 2497, 1998, 109...\n",
      "22522     [101, 2017, 2031, 2042, 8184, 8534, 2013, 9260...\n",
      "36661     [101, 2065, 2115, 2063, 1996, 5310, 2071, 2017...\n",
      "98165     [101, 3087, 4699, 1999, 3773, 1996, 2197, 2544...\n",
      "                                ...                        \n",
      "147642    [101, 2293, 2023, 28516, 1045, 2074, 2293, 202...\n",
      "52296     [101, 8756, 3931, 2128, 15773, 2044, 1037, 271...\n",
      "141471    [101, 1045, 2123, 2102, 2903, 2008, 1996, 1276...\n",
      "5317      [101, 2174, 2017, 2134, 2102, 3696, 2115, 1008...\n",
      "26817             [101, 5314, 1998, 2417, 7442, 10985, 102]\n",
      "Name: text, Length: 319, dtype: object\n",
      "(319,)\n",
      "Wall time: 6.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(tokenized)\n",
    "print(tokenized.shape)\n",
    "#print(df_ups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1593,)\n",
      "(1593, 512)\n",
      "(1593, 512)\n"
     ]
    }
   ],
   "source": [
    "print(tokenized.shape)\n",
    "print(padded.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26447     [101, 2004, 4842, 15776, 1998, 1040, 7274, 144...\n",
      "155507    [101, 1038, 2094, 5443, 10930, 2497, 1998, 109...\n",
      "22522     [101, 2017, 2031, 2042, 8184, 8534, 2013, 9260...\n",
      "36661     [101, 2065, 2017, 1005, 2128, 1996, 5310, 1010...\n",
      "98165     [101, 3087, 4699, 1999, 3773, 1996, 2197, 2544...\n",
      "Name: text, dtype: object\n",
      "[[ 101 2004 4842 ...    0    0    0]\n",
      " [ 101 1038 2094 ...    0    0    0]\n",
      " [ 101 2017 2031 ...    0    0    0]\n",
      " [ 101 2065 2017 ...    0    0    0]]\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized.head())\n",
    "print(padded[0:4,:])\n",
    "\n",
    "print(attention_mask[0:4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Самая длительная процедура. Оптимизация векторов.\n",
    "2. На ноуте 330 значений оптимизировалось 5 часов (оставил вычисления с ноута, 330 строк 5 часов 13 мин.\n",
    "3. На старой станции, 3000 значений оптимизирует 40мин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5964c015f4564109828576fb7f04b827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5h 13min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 10\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Получим матрицы признаков и таргетов.\n",
    "2. 9 строк признаков не вошло в эмбединг, уберем эти строки и из таргетов.\n",
    "3. Тут оставил результаты расчета на ноуте, на нем пишу отчет.\n",
    "4. Для меня загадка, почему схлопнулось до 6 столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 6)\n",
      "43\n",
      "(310,)\n"
     ]
    }
   ],
   "source": [
    "X_ = np.concatenate(embeddings)\n",
    "print(X_.shape)\n",
    "y_ = df_['toxic'][0:310]\n",
    "print(sum(y_))\n",
    "y_np = y_.values\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(y_df.head())\\nprint(y_df.tail())\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_df = pd.DataFrame(data=X_)\n",
    "display(X_df.head())\n",
    "display(X_df.tail())\n",
    "y_df = pd.Series(data=y_np)\n",
    "X_df.to_csv(r'c:\\%Users%\\datasets\\X_df.csv')  \n",
    "y_df.to_csv(r'c:\\%Users%\\datasets\\y_df.csv')  \n",
    "print(y_df.head())\n",
    "print(y_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импортировал значения станции\n",
    "2. Как никак 1580 значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.221975  0.645929  0.120793  0.395917  0.027843  1.044683\n",
      "1  0.238338  0.547478  0.241995  0.466450  0.031583  1.018048\n",
      "2  0.273470  0.469837  0.228394  0.515334 -0.023717  1.003967\n",
      "3  0.231933  0.520798  0.254784  0.476044 -0.080721  0.982087\n",
      "4  0.196502  0.582510  0.103276  0.373847  0.028609  0.884021\n",
      "             0         1         2         3         4         5\n",
      "1575  0.106456  0.596228  0.093451  0.359686  0.057490  1.001742\n",
      "1576  0.249963  0.454072  0.149404  0.359429 -0.024041  0.918310\n",
      "1577  0.221888 -0.177940 -0.009043 -0.106122  0.102372  0.208950\n",
      "1578  0.185396  0.538506  0.247365  0.517950  0.000176  0.999980\n",
      "1579  0.225921  0.695862  0.139792  0.463811  0.131721  1.012390\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "      0\n",
      "1575  0\n",
      "1576  0\n",
      "1577  1\n",
      "1578  0\n",
      "1579  0\n"
     ]
    }
   ],
   "source": [
    "X_df = pd.read_csv(r'c:\\%Users%\\datasets\\X_df1.csv',index_col=[0])  \n",
    "y_df = pd.read_csv(r'c:\\%Users%\\datasets\\y_df1.csv',index_col=[0])  \n",
    "print(X_df.head())\n",
    "print(X_df.tail())\n",
    "print(y_df.head())\n",
    "print(y_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Разделение наборов на train, test, таргеты и признаки <a class=\"anchor\" id=\"2.2.Таргет_Призн\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(1264, 6)\n",
      "(1264, 1)\n",
      "             0         1         2         3         4         5\n",
      "243   0.273652  0.448398  0.154735  0.467910 -0.005949  0.962566\n",
      "137   0.233285  0.550384  0.378357  0.539977 -0.034335  1.011030\n",
      "36    0.214641  0.591989  0.134738  0.442989  0.014816  1.108101\n",
      "1511  0.193792  0.564257  0.211581  0.420615  0.003101  1.012922\n",
      "189   0.213057  0.293138  0.249988  0.431603 -0.129562  0.916270\n",
      "             0         1         2         3         4         5\n",
      "594   0.135012  0.536017  0.113799  0.427400  0.011443  1.092909\n",
      "726   0.210975  0.580792  0.193263  0.357734  0.057507  0.991030\n",
      "970   0.240265  0.388861  0.216818  0.434109 -0.005781  1.044691\n",
      "1425  0.262905  0.428502  0.246064  0.504907 -0.043291  1.029067\n",
      "1567  0.215138  0.485129  0.228926  0.423884  0.005770  1.052290\n",
      "      0\n",
      "243   0\n",
      "137   0\n",
      "36    0\n",
      "1511  0\n",
      "189   0\n",
      "      0\n",
      "594   0\n",
      "726   0\n",
      "970   0\n",
      "1425  0\n",
      "1567  0\n",
      "test\n",
      "(316, 6)\n",
      "(316, 1)\n",
      "             0         1         2         3         4         5\n",
      "161   0.523976 -0.158784  0.160330  0.060359  0.195805 -0.055453\n",
      "588  -0.388708 -0.345176 -0.057929  0.375277  0.306177  0.310942\n",
      "375   0.153519  0.514995  0.193744  0.408021 -0.018122  1.049301\n",
      "1423  0.224636  0.503462  0.247430  0.407041  0.044483  1.061959\n",
      "932   0.152688  0.600490  0.160482  0.473585  0.039377  1.100996\n",
      "             0         1         2         3         4         5\n",
      "1229  0.265961 -0.187632  0.004856  0.147216  0.081078  0.354179\n",
      "144   0.256470  0.609793  0.182437  0.516507 -0.049911  1.042248\n",
      "436   0.133385  0.600803  0.089472  0.284762  0.042302  1.000427\n",
      "1093  0.197196  0.609817  0.099896  0.345003  0.032945  1.003956\n",
      "869   0.264532  0.567568  0.141930  0.435133  0.034631  1.001470\n",
      "      0\n",
      "161   0\n",
      "588   1\n",
      "375   0\n",
      "1423  0\n",
      "932   0\n",
      "      0\n",
      "1229  0\n",
      "144   0\n",
      "436   0\n",
      "1093  0\n",
      "869   0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2)\n",
    "print('train')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train.head())\n",
    "print(X_train.tail())\n",
    "print(y_train.head())\n",
    "print(y_train.tail())\n",
    "\n",
    "print('test')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test.head())\n",
    "print(X_test.tail())\n",
    "print(y_test.head())\n",
    "print(y_test.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Хотя, предварительные оценки показали, и так все неплохо получается.\n",
    "2. Правильно будет устранить дисбаланс в таргетах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.106804\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучение и  тестирование моделей <a class=\"anchor\" id=\"3.Обучение_мод\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Сложная валидация с Ucampling <a class=\"anchor\" id=\"3.1.LR\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. После upsampling делать валидаци некоректно, поэтому стандартная процедура скоректирована.\n",
    "2. Вначале отделил test/train\n",
    "3. Задаю модель\n",
    "4. На внешнем цикле меняю гиперпараметры\n",
    "5. Потом делю выборку train на фолды  с помощью KFold в каждом фолде 4/5 это train, а 1/5 это valid. \n",
    "6. Провожу Upsamling SMOT (необходимо инсталировать в Conda или в Colab). У меня pip install не работал корректно в Conde.\n",
    "7. Обучаю на X_train_fold_upsample, y_train_fold_upsample\n",
    "8. Проверяю на валидность, выборка valid не сэмплированная. \n",
    "9. Нахожу метрику score = f1_score(y_val_fold, model_obj.predict(X_val_fold))\n",
    "9. Собрал результаты в многомерный список, перевел в Датафрейм\n",
    "10. Сделал scores_df.groupby('C', as_index=False).mean()\n",
    "11. Результаты почти плоские. Выделил как оптимальный C=1\n",
    "12. Проведу тест на тестовой выборке, с С=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n",
      "Средний таргет после крутого апсемпла: 0    0.5\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0625</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.853611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1250</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.853575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2500</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.853389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.856984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.859106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.855433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.855726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fold  f1_score\n",
       "C                     \n",
       "0.0625   2.0  0.853611\n",
       "0.1250   2.0  0.853575\n",
       "0.2500   2.0  0.853389\n",
       "0.5000   2.0  0.856984\n",
       "1.0000   2.0  0.859106\n",
       "2.0000   2.0  0.855433\n",
       "4.0000   2.0  0.855726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 758 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr= LogisticRegression()\n",
    "param={\"C\" :[0.0625, 0.125,0.25,0.5,1,2, 4],\n",
    "        \"class_weight\" : ['balanced'],\n",
    "        \"solver\":['liblinear']}\n",
    "model = lr\n",
    "kf = KFold(n_splits=5)\n",
    "scores = []\n",
    "#kv = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for g in ParameterGrid(param):\n",
    "    model.set_params(**g)\n",
    "#    print(model)\n",
    "#    print(g)\n",
    "#    print(**g)\n",
    "#    print(X_train)\n",
    "#    print(y_train)\n",
    "#    print(kf)\n",
    "    \n",
    "    for i, (train_fold_index, val_fold_index) in enumerate(kf.split(X_train)):\n",
    "        #print(f\"Fold {i}:\")\n",
    "        #print(f\"  Train: index={train_fold_index}\")\n",
    "        #print(f\"  Test:  index={val_fold_index}\")\n",
    "\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_fold_index], y_train.iloc[train_fold_index]\n",
    "        # Get the validation data\n",
    "        X_val_fold, y_val_fold = X_train.iloc[val_fold_index], y_train.iloc[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "        X_train_fold_upsample, y_train_fold_upsample = smoter.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "        print(\"Средний таргет после крутого апсемпла:\", y_train_fold_upsample.mean())\n",
    "        # Fit the model on the upsampled training data\n",
    "#        print('X_train_fold_upsample',X_train_fold_upsample.shape)\n",
    "#        print('y_train_fold_upsample',y_train_fold_upsample.shape)\n",
    "#        print('g',g)\n",
    "        model_obj = model.fit(X_train_fold_upsample, y_train_fold_upsample.values.ravel())\n",
    "        # Score the model on the (non-upsampled) validation data\n",
    "\n",
    "        score = f1_score(y_val_fold, model_obj.predict(X_val_fold))\n",
    "        scores.append([g[\"C\"],i,score])\n",
    "scores_df = pd.DataFrame(data = scores, columns = ['C', 'Fold', 'f1_score'])\n",
    "\n",
    "display(scores_df.groupby('C', as_index=\"C\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Финальное тестирование <a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_test: 0.8314606741573033\n",
      "Wall time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr= LogisticRegression()\n",
    "param={\"C\" :1,\n",
    "        \"class_weight\" : 'balanced',\n",
    "        \"solver\":'liblinear'}\n",
    "model = lr\n",
    "model.set_params(**param)\n",
    "X_train_fold_upsample, y_train_fold_upsample = smoter.fit_resample(X_train, y_train)\n",
    "model_obj = model.fit(X_train_fold_upsample, y_train_fold_upsample.values.ravel())\n",
    "# Score the model on the (non-upsampled) validation data\n",
    "\n",
    "score = f1_score(y_test, model_obj.predict(X_test))\n",
    "print('f1_score_test:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Вывод <a class=\"anchor\" id=\"4.Вывод\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Задача оценки токсичных коментариев сделана с использованием предтестированных моделей BERT.\n",
    "2. Данные предварительно очищены. Выявлен дисбаланс по таргетам. Оставлять его нельзя.\n",
    "3. Токенизация, эмбединг и padding выполнены с помощью BERT.\n",
    "4. Самая длительная процедура - оптимизация векторов признаков, после padding. Выполняется достаточно долго - на ноуте получилось 5 часов 300 твитов. На системном блоке 40 минут, 1600 твитов.\n",
    "5. После оптимизации, получилось всего 6 признаков. \n",
    "6. Было выполнено разделение target и признаки, train и test.\n",
    "7. Затем был проведен Upsampling.\n",
    "7. Для предсказаний использовалась линейная регрессия. Результат хороший:\n",
    "        A. f1 на валидации 85%,\n",
    "        B. f1 на test 83%.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2980,
    "start_time": "2022-11-26T18:05:11.824Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-26T18:05:14.806Z"
   },
   {
    "duration": 181,
    "start_time": "2022-11-26T18:05:14.810Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.993Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.994Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.995Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.996Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.997Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.998Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:14.999Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.000Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.001Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.003Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.004Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.005Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.006Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.007Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.008Z"
   },
   {
    "duration": 1,
    "start_time": "2022-11-26T18:05:15.039Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.041Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.044Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.046Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.047Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.048Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-26T18:05:15.049Z"
   },
   {
    "duration": 3152,
    "start_time": "2022-11-26T18:08:04.732Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-26T18:08:07.886Z"
   },
   {
    "duration": 175,
    "start_time": "2022-11-26T18:08:07.890Z"
   },
   {
    "duration": 180,
    "start_time": "2022-11-26T18:08:08.067Z"
   },
   {
    "duration": 13111,
    "start_time": "2022-11-26T18:08:08.249Z"
   },
   {
    "duration": 362,
    "start_time": "2022-11-26T18:08:21.362Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-26T18:08:21.725Z"
   },
   {
    "duration": 99,
    "start_time": "2022-11-26T18:08:21.744Z"
   },
   {
    "duration": 79196,
    "start_time": "2022-11-26T18:08:21.845Z"
   },
   {
    "duration": 73534,
    "start_time": "2022-11-26T18:09:41.042Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-26T18:10:54.577Z"
   },
   {
    "duration": 26,
    "start_time": "2022-11-26T18:10:54.584Z"
   },
   {
    "duration": 102,
    "start_time": "2022-11-26T18:10:54.611Z"
   },
   {
    "duration": 48,
    "start_time": "2022-11-26T18:10:54.716Z"
   },
   {
    "duration": 205,
    "start_time": "2022-11-26T18:10:54.838Z"
   },
   {
    "duration": 196,
    "start_time": "2022-11-26T18:10:55.045Z"
   },
   {
    "duration": 108,
    "start_time": "2022-11-26T18:10:55.243Z"
   },
   {
    "duration": 202,
    "start_time": "2022-11-26T18:10:55.353Z"
   },
   {
    "duration": 80886,
    "start_time": "2022-11-26T18:10:55.557Z"
   },
   {
    "duration": 13396,
    "start_time": "2022-11-26T18:12:16.445Z"
   },
   {
    "duration": 113784,
    "start_time": "2022-11-26T18:12:29.843Z"
   },
   {
    "duration": 34701,
    "start_time": "2022-11-26T18:14:23.629Z"
   },
   {
    "duration": 80563,
    "start_time": "2022-11-26T18:14:58.336Z"
   },
   {
    "duration": 12808,
    "start_time": "2022-11-26T18:16:18.901Z"
   },
   {
    "duration": 393,
    "start_time": "2022-11-26T18:16:31.710Z"
   },
   {
    "duration": 3908,
    "start_time": "2023-01-14T10:56:41.731Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-14T10:56:45.641Z"
   },
   {
    "duration": 163,
    "start_time": "2023-01-14T10:56:46.420Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-14T10:58:37.457Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-14T11:08:35.434Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-14T11:08:37.064Z"
   },
   {
    "duration": 31,
    "start_time": "2023-01-14T11:08:37.742Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-14T11:09:04.020Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-14T11:09:05.172Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-14T11:09:10.659Z"
   },
   {
    "duration": 155,
    "start_time": "2023-01-14T11:10:28.404Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-14T11:10:50.016Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-14T11:11:10.704Z"
   },
   {
    "duration": 5252,
    "start_time": "2023-02-06T05:50:57.546Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-06T05:51:02.800Z"
   },
   {
    "duration": 202,
    "start_time": "2023-02-06T05:51:02.806Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-06T05:51:03.011Z"
   },
   {
    "duration": 207,
    "start_time": "2023-02-06T05:51:03.020Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.229Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.230Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.232Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.232Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.244Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.245Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.247Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.248Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.249Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.249Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.250Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.251Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.252Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.253Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.254Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.255Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-06T05:51:03.257Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-06T05:51:18.212Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-06T05:51:18.766Z"
   },
   {
    "duration": 82,
    "start_time": "2023-02-06T05:51:40.586Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-06T05:51:40.897Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-06T05:51:41.433Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-06T05:51:42.357Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-06T05:51:42.553Z"
   },
   {
    "duration": 1173,
    "start_time": "2023-02-06T05:51:43.310Z"
   },
   {
    "duration": 1047,
    "start_time": "2023-02-06T05:51:44.485Z"
   },
   {
    "duration": 1920,
    "start_time": "2023-02-06T05:51:45.534Z"
   },
   {
    "duration": 188,
    "start_time": "2023-02-06T05:51:47.457Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-06T05:51:47.647Z"
   },
   {
    "duration": 49,
    "start_time": "2023-02-06T05:51:47.658Z"
   },
   {
    "duration": 4280,
    "start_time": "2023-02-06T05:51:47.708Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-06T05:51:51.990Z"
   },
   {
    "duration": 46,
    "start_time": "2023-02-06T05:51:51.999Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-06T05:51:52.047Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-06T05:51:52.060Z"
   },
   {
    "duration": 77,
    "start_time": "2023-02-06T05:51:52.071Z"
   },
   {
    "duration": 108,
    "start_time": "2023-02-06T05:51:52.150Z"
   },
   {
    "duration": 104,
    "start_time": "2023-02-06T05:51:52.345Z"
   },
   {
    "duration": 114335,
    "start_time": "2023-02-06T05:51:52.451Z"
   },
   {
    "duration": 21397,
    "start_time": "2023-02-06T05:53:51.137Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-06T05:54:12.536Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-06T05:54:12.545Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-06T05:54:33.155Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-06T05:54:39.574Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-06T05:54:43.187Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
